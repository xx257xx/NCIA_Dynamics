{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fb6f511-54d1-4b2d-954e-d75f7c729032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Zongyi Li\n",
    "This file is the Fourier Neural Operator for 1D problem such as the (time-independent) Burgers equation discussed in Section 5.1 in the [paper](https://arxiv.org/pdf/2010.08895.pdf).\n",
    "\"\"\"\n",
    "#del F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "from utilities3 import *\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "################################################################\n",
    "#  1d fourier layer\n",
    "################################################################\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, modes, width, depth):\n",
    "        super(FNO1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        #self.padding = 2 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(3, self.width, bias=False) # input channel is 2: (a(x), x)\n",
    "        \n",
    "        self.fouriers = nn.ModuleList([SpectralConv1d(self.width, self.width, self.modes1) for i in range(self.depth)])\n",
    "\n",
    "        self.relu = nn.GELU()\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128,  bias=False)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        \n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc0(x)\n",
    "        #print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        #print(x.shape)\n",
    "        # x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        \n",
    "        for i in range(self.depth):\n",
    "            \n",
    "            x1 = self.fouriers[i](x)\n",
    "        \n",
    "            x = self.relu(x1)\n",
    "\n",
    "        # x = x[..., :-self.padding] # pad the domain if input is non-periodic\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x = shape[0], shape[1]\n",
    "        gridx = torch.tensor(np.linspace(0, 60, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1).repeat([batchsize, 1, 1])\n",
    "        return gridx.to(device)\n",
    "\n",
    "################################################################\n",
    "#  configurations\n",
    "################################################################\n",
    "ntrain = 1000\n",
    "ntest = 100\n",
    "\n",
    "sub = 2**3 #subsampling rate\n",
    "h = 2**13 // sub #total grid size divided by the subsampling rate\n",
    "s = h\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "epochs = 500\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 1 #16\n",
    "width = 64\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1c563c3-c668-4d53-8b10-794f267c36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# read data\n",
    "################################################################\n",
    "\n",
    "# Data is of the shape (number of samples, grid size)\n",
    "\n",
    "\n",
    "for datas in ['TRAIN']:\n",
    "\n",
    "    batch_size = 40\n",
    "\n",
    "    with open(\"./data/\" + datas + \".pickle\",\"rb\") as fr:\n",
    "        train_raw_set_loaded = pickle.load(fr)\n",
    "    \n",
    "    if datas == 'TRAIN' or datas == 'Burger_GRF_0.01_50000':\n",
    "        with open(\"./data/TEST.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    elif datas == 'Burger_vicious_GRF_0.05_10000' or datas == 'Burger_vicious_GRF_0.05_800':\n",
    "        with open(\"./data/Burger_vicious_GRF_0.05_test.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    elif datas == '1d_Heat_GRF_0.05_10000_1024':\n",
    "        with open(\"./data/1d_Heat_GRF_0.05_200_1024.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    elif datas == 'Integration_GRF_0.05_10000':\n",
    "        with open(\"./data/Integration_GRF_0.05_test.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    elif datas == 'new_KdV_GRF_0.05_10000': \n",
    "        with open(\"./data/new_KdV_GRF_0.05_test.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    else:\n",
    "        with open(\"./data/Burger_GRF_0.05_test.pickle\",\"rb\") as fr:\n",
    "            test_raw_set_loaded = pickle.load(fr)\n",
    "    \n",
    "    \n",
    "    x_train = torch.tensor(train_raw_set_loaded['train_X'])\n",
    "    y_train = torch.tensor(train_raw_set_loaded['train_Y'])\n",
    "    x_test = torch.tensor(test_raw_set_loaded['train_X'])\n",
    "    y_test = torch.tensor(test_raw_set_loaded['train_Y'])\n",
    "\n",
    "    y_train = y_train.unsqueeze(-1)\n",
    "    y_test = y_test.unsqueeze(-1)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=100, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e7a03-5588-4719-9104-5aff727501bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172353\n",
      "0 29.723653628031414 9.074326578776041\n",
      "1 9.148514149983724 4.140504455566406\n",
      "2 2.7164896138509116 4.631343587239583\n",
      "3 2.0866188939412433 1.2090861002604167\n",
      "4 0.9787272262573242 1.4500544230143229\n",
      "5 0.6740607643127441 0.843336550394694\n",
      "6 0.48896549224853514 0.7652108510335286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "re = 3\n",
    "\n",
    "model = FNO1d(10, 64, 2).cuda()\n",
    "\n",
    "print(count_params(model))\n",
    "\n",
    "ntrain = len(x_train)\n",
    "ntest = len(x_test)\n",
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=re*1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "myloss2 = LpLoss(size_average=False)\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "\n",
    "        #mse = F.mse_loss(out.view(batch_size, -1), y.view(batch_size, -1), reduction='mean')\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward() # use the l2 relative loss\n",
    "\n",
    "        optimizer.step()\n",
    "        #train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "\n",
    "            out = model(x)\n",
    "            test_l2 += myloss2(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    #train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "    \n",
    "    print(ep, train_l2, test_l2)\n",
    "\n",
    "    t2 = default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e401ea2-a17c-4e95-81ba-e1c00aff7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[0][:,1].cpu())\n",
    "plt.plot(x[0][:,0].cpu())\n",
    "plt.plot(x[1][:,0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeed833-4c9e-46de-a67d-6b9b812c4699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNO",
   "language": "python",
   "name": "fno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
